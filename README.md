# DE-STRESS: A user-friendly web application for the evaluation of protein designs - Decoy Analysis

## Overview

This repository contains the python code and the output for the decoy structure analysis included in 
the DE-STRESS paper. This decoy analysis gives one example of how the metrics in DE-STRESS could be 
used. A set of 10 experimentally-determined structures along with 20 folding decoys were randomly 
sampled from the 3DRobot_set. Using the DE-STRESS web server, we generated and exported metrics for 
all of these structures. After this, the metrics were normalised with min-max scaling, so that the 
features ranged between 0 and 1. Finally, principal component analysis (pca) was performed on the 
normalised data set. 

By plotting the first two principal components, the experimentally-determined structures and 
their decoys formed clusters. Furthermore, the experimentally-determined structures were close to, 
but distinct from, the main cluster, indicating that the metrics included in DE-STRESS could be used
to automatically identify high-quality structure models using machine learning. 

## Data

### Data Set used for Decoy Analysis

The data set used for the decoy analysis was created using the 3DRobot_set generated by 
3DRobot [Deng et al., 2016](https://doi.org/10.1093/bioinformatics/btv601). A set of 10 
experimentally-determined structures along with 20 folding decoys were randomly sampled from 
the 3DRobot_set. After some pre-processing, the DE-STRESS webserver was used to generate metrics 
for this data and the final data set is saved as `de-stress_output/combined_data.csv`.


### Creating the Data Set

In order to recreate the full analysis, the 3DRobot_set can be downloaded from 
[here](https://zhanglab.dcmb.med.umich.edu/3DRobot/decoys/). The `3DRobot_set.tar.bz2` folder
was extracted in the `data/` folder in this repo. After all the subfolders were extracted,
the `fixing_pdb_files.py` script was ran. This script is needed as the decoy pdb files 
generated by 3DRobot have the element column missing. Also, some of the pdb files contained 
hydrogen atoms which are not accepted by a lot of the metrics ran in DE-STRESS. Both of these 
issues needed to be addressed before running these pdb files through the DE-STRESS web server. 
**(Note: This script takes quite a bit of time to run)**.

After the pdb files had been fixed, the `sampling_pdb_files.py` script was ran to sample 10 
experimentally-determined structures and 20 decoys were randomly sampled for each one. 
The decoy structures in the 3DRobot set have RMSD ranging from 0 to 12 Ã…, so the random sampling 
was done to ensure a spread across this range. 

Once the structures had been sampled, they were 
ran through the DE-STRESS web server in 10 batches and the data was downloaded as `.csv` files. 
These `.csv` files are saved as;

1. `de-stress_output/1N8VA.csv`
2. `de-stress_output/1ZI8A.csv`
3. `de-stress_output/2HS1A.csv`
4. `de-stress_output/2YHSA.csv`
5. `de-stress_output/3CHBD.csv`
6. `de-stress_output/3D32A.csv`
7. `de-stress_output/3MMHA.csv`
8. `de-stress_output/3NJNA.csv`
9. `de-stress_output/3WCQA.csv`
10. `de-stress_output/3WDCA.csv`.
                                 
Finally the `data_prep.py` script was used to combine all the `.csv` files together, to drop 
some columns that were not needed and to create the `decoy or native` and `pdb id` columns.
This data set was then saved as `de-stress_output/combined_data.csv`. 

## Principal Component Analysis (PCA)

### Scaling the features

Before performing PCA on the `de-stress_output/combined_data.csv`, we scaled the features so that
the values were between 0 and 1. This is because PCA is extremely sensitive to the magnitude of
the values and higher magnitude features (e.g energy function values) could skew the analysis. We
chose to normalise the features with min-max scaling rather than using standardisation, as some of
the features did not look like they had a Gaussian distribution. An example of this is shown in the 
plot below:


[<img src=./analysis/hist_dfire2.png>]()



